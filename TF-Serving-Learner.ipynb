{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Ra5G6PYy4f"
      },
      "source": [
        "<h2 align=\"center\"> Deploy Models with TensorFlow Serving and Docker</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gct6OAi6Yy4h"
      },
      "source": [
        "### Task 2: Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZQhSNW-CZUZh"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVg0wxs2Yy4i",
        "outputId": "76bb410e-d399-4d31-c62f-1a1554f2acf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Id,ProductId,UserId,ProfileName,HelpfulnessNumerator,HelpfulnessDenominator,Score,Time,Summary,Text\n",
            "184502,B001BCVY4W,A1JMR1N9NBYJ1X,Mad Ethyl Flint,0,0,4,1228176000,Doesn't look like catfood!,\"When you first open the can, it looks like something you would eat.  And no catfood smell! Nice sized chunks of chicken and vegetables in a lot of gravy.<br /><br />That being said, Ms Casiopia lapped up all the gravy and left the rest.  This however is not the product's fault as she has done this before with other catfoods<br /><br />I would have given it 5 stars, but since I won't be purchasing it, I gave it 4.  If your cat will eat chunks and vegetables, this product is for you.<br /><br />I have donated the remainder of the package to a less fortunate friend.<br /><br />Thank you.\"\n"
          ]
        }
      ],
      "source": [
        "#Souce: https://www.kaggle.com/snap/amazon-fine-food-reviews/data\n",
        "!head -n 2 train.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SRnfDKDKYy4j"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "def load_data(file_path,num_samples):\n",
        "  df = pd.read_csv(file_path,usecols=[6,9],nrows=num_samples)\n",
        "  df.columns = ['rating','title']\n",
        "\n",
        "  text = df['title'].tolist()\n",
        "  text = [str(t).encode('ascii','replace') for t in text]\n",
        "  text = np.array(text,dtype=object)[:]\n",
        "\n",
        "  labels = df['rating'].tolist()\n",
        "  labels = [1 if i>=4 else 0 if i==3 else -1 for i in labels]\n",
        "  labels = np.array(pd.get_dummies(labels),dtype=int)[:]\n",
        "\n",
        "  return labels, text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-rrXJowYy4j",
        "outputId": "ce88b075-0552-4362-cb32-03dee3602e7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tmp_labels ,tmp_text=load_data('train.csv',100)\n",
        "tmp_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPeAqgOEYy4j"
      },
      "source": [
        "### Task 3: Build the Classification Model using TF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QdAjtF6jYy4j"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "\n",
        "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\n",
        "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\n",
        "def get_model():\n",
        "  hub_layer=hub.KerasLayer('https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1',\n",
        "                           out_shape=[50],\n",
        "                           input_shape=[],\n",
        "                           dtype=tf.string,\n",
        "                           name='input',\n",
        "                           trainable=False\n",
        "                           )\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(hub_layer)\n",
        "  model.add(tf.keras.layers.Dense(16,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(3,activation='softmax',name='output'))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['Accuracy'])\n",
        "  model.summary()\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slMwVkeHYy4j",
        "outputId": "5533161d-c765-46b6-e297-d1e7a679b1fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
              "array([[ 0.05650096,  0.2567145 ,  0.24404189,  0.14395264, -0.05569138,\n",
              "        -0.10513686,  0.09544804,  0.3080969 , -0.218672  , -0.03048538,\n",
              "        -0.19036278,  0.01005417,  0.11541114, -0.14860378,  0.03914931,\n",
              "        -0.2561884 , -0.15442336,  0.12836292,  0.0469152 , -0.1500514 ,\n",
              "        -0.13068351, -0.01958709,  0.09192696,  0.1208052 , -0.12291992,\n",
              "        -0.04548305, -0.36792612,  0.05125156,  0.09797382, -0.10217863,\n",
              "        -0.1965521 ,  0.1552313 , -0.05881736, -0.16426983,  0.06646369,\n",
              "         0.05789639,  0.1542162 , -0.24014738,  0.11075414, -0.10756174,\n",
              "        -0.01679449, -0.01877424,  0.18602087,  0.2623015 , -0.3829217 ,\n",
              "        -0.34895867, -0.08689779,  0.02295742,  0.03787762, -0.02646483],\n",
              "       [-0.01533648,  0.2517981 ,  0.15771465,  0.10011643, -0.03027005,\n",
              "        -0.09655963,  0.10035348, -0.13405894, -0.13515756,  0.15999079,\n",
              "        -0.0257801 ,  0.01482286,  0.17336626,  0.02416893, -0.02589497,\n",
              "        -0.2256546 , -0.10834837,  0.05091727, -0.01329861, -0.1124052 ,\n",
              "        -0.04385714, -0.16535808,  0.07700986, -0.04862161,  0.05802561,\n",
              "         0.06278763, -0.10784025,  0.11745881,  0.07221924, -0.15103991,\n",
              "        -0.07155664, -0.00210648, -0.00439631, -0.24547553, -0.16631113,\n",
              "        -0.2056742 , -0.05564746, -0.14419016, -0.12905043, -0.05601301,\n",
              "        -0.10155824, -0.18731159,  0.1180155 ,  0.277938  , -0.02531946,\n",
              "         0.02398384, -0.12459337, -0.03263709,  0.00738646, -0.07372268]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "embed = hub.load('https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1')\n",
        "embeddings = embed(['this is a test','look at the embeddings'])\n",
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQEPR5o9Yy4k"
      },
      "source": [
        "### Task 4: Define Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOxiqGSYYy4k"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WStSIpQSYy4k"
      },
      "source": [
        "### Task 5: Train and Export Model as Protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iqvl8k-Yy4k"
      },
      "outputs": [],
      "source": [
        "#%%writefile -a train.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcU3DxbLYy4k"
      },
      "source": [
        "### Task 6: Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_LiK-ufYy4l"
      },
      "source": [
        "#### Negative Review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f13OMy7zYy4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi-IJ_ywYy4l"
      },
      "source": [
        "#### Positive Review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFFcWH3FYy4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdq7sLbUYy4l"
      },
      "source": [
        "### Task : TensorFlow Serving with Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8L1Nu_iYy4l"
      },
      "source": [
        "`docker pull tensorflow/serving`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRx8wWwEYy4m"
      },
      "source": [
        "`docker run -p 8500:8500 \\\n",
        "            -p 8501:8501 \\\n",
        "            --mount type=bind,\\\n",
        "            source=amazon_review/,\\\n",
        "            target=/models/amazon_review \\\n",
        "            -e MODEL_NAME=amazon_review \\\n",
        "            -t tensorflow/serving`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zCYnF5mYy4m"
      },
      "source": [
        "### Task : Setup a REST Client to Perform Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLQnW9XkYy4m"
      },
      "source": [
        "#### Perform Model Prediction\n",
        "\n",
        "##### Support for gRPC and REST\n",
        "\n",
        "- TensorFlow Serving supports\n",
        "    - Remote Procedure Protocal (gRPC)\n",
        "    - Representational State Transfer (REST)\n",
        "- Consistent API structures\n",
        "- Server supports both standards simultaneously\n",
        "- Default ports:\n",
        "    - RPC: 8500\n",
        "    - REST: 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LinyRl61Yy4m"
      },
      "source": [
        "#### Predictions via REST\n",
        "\n",
        "- Standard HTTP POST requests\n",
        "- Response is a JSON body with the prediction\n",
        "- Request from the default or specific model\n",
        "\n",
        "Default URI scheme:\n",
        "\n",
        "`http://{HOST}:{PORT}/v1/models/{MODEL_NAME}`\n",
        "\n",
        "Specific model versions:\n",
        "\n",
        "`http://{HOST}:{PORT}/v1/models/{MODEL_NAME}[/versions/{MODEL_VERSION}]:predict`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NND75SMZUsP"
      },
      "outputs": [],
      "source": [
        "%%writefile tf_serving_rest_client.py\n",
        "import json\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "def get_rest_url(model_name, host='127.0.0.1', port='8501', verb='predict', version=None):\n",
        "    \"\"\" generate the URL path\"\"\"\n",
        "    url = \"http://{host}:{port}/v1/models/{model_name}\".format(host=host, port=port, model_name=model_name)\n",
        "    if version:\n",
        "        url += 'versions/{version}'.format(version=version)\n",
        "    url += ':{verb}'.format(verb=verb)\n",
        "    return url\n",
        "\n",
        "\n",
        "def get_model_prediction(model_input, model_name='amazon_review', signature_name='serving_default'):\n",
        "    \"\"\" no error handling at all, just poc\"\"\"\n",
        "\n",
        "    url = get_rest_url(model_name)\n",
        "    #In the row format, inputs are keyed to instances key in the JSON request.\n",
        "    #When there is only one named input, specify the value of instances key to be the value of the input:\n",
        "    data = {\"instances\": [model_input]}\n",
        "\n",
        "    rv = requests.post(url, data=json.dumps(data))\n",
        "    if rv.status_code != requests.codes.ok:\n",
        "        rv.raise_for_status()\n",
        "\n",
        "    return rv.json()['predictions']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    print(\"\\nGenerate REST url ...\")\n",
        "    url = get_rest_url(model_name='amazon_review')\n",
        "    print(url)\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nEnter an Amazon review [:q for Quit]\")\n",
        "        if sys.version_info[0] <= 3:\n",
        "            sentence = input()\n",
        "        if sentence == ':q':\n",
        "            break\n",
        "        model_input = sentence\n",
        "        model_prediction = get_model_prediction(model_input)\n",
        "        print(\"The model predicted ...\")\n",
        "        print(model_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuEDGizMYy4n"
      },
      "source": [
        "### Task : Setup a gRPC Client to Perform Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg2zk8w8Yy4o"
      },
      "source": [
        "Modified from [https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_client.py](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_client.py#L152)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0tqWfrtYy4o"
      },
      "source": [
        "#### Predictions via gRPC\n",
        "\n",
        "More sophisticated client-server connections\n",
        "\n",
        "- Prediction data has to be converted to the Protobuf format\n",
        "- Request types have designated types, e.g. float, int, bytes\n",
        "- Payloads need to be converted to base64\n",
        "- Connect to the server via gRPC stubs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvLwL9UvYy4o"
      },
      "source": [
        "#### gRPC vs REST: When to use which API standard\n",
        "\n",
        "- Rest is easy to implement and debug\n",
        "- RPC is more network efficient, smaller payloads\n",
        "- RPC can provide much faster inferences!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKJVOjDlZUvc"
      },
      "outputs": [],
      "source": [
        "%%writefile tf_serving_grpc_client.py\n",
        "import sys\n",
        "import grpc\n",
        "from grpc.beta import implementations\n",
        "import tensorflow as tf\n",
        "from tensorflow_serving.apis import predict_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2, get_model_metadata_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "\n",
        "def get_stub(host='127.0.0.1', port='8500'):\n",
        "    channel = grpc.insecure_channel('127.0.0.1:8500')\n",
        "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "    return stub\n",
        "\n",
        "\n",
        "def get_model_prediction(model_input, stub, model_name='amazon_review', signature_name='serving_default'):\n",
        "    \"\"\" no error handling at all, just poc\"\"\"\n",
        "    request = predict_pb2.PredictRequest()\n",
        "    request.model_spec.name = model_name\n",
        "    request.model_spec.signature_name = signature_name\n",
        "    request.inputs['input_input'].CopyFrom(tf.make_tensor_proto(model_input))\n",
        "    response = stub.Predict.future(request, 5.0)  # 5 seconds\n",
        "    return response.result().outputs[\"output\"].float_val\n",
        "\n",
        "\n",
        "def get_model_version(model_name, stub):\n",
        "    request = get_model_metadata_pb2.GetModelMetadataRequest()\n",
        "    request.model_spec.name = 'amazon_review'\n",
        "    request.metadata_field.append(\"signature_def\")\n",
        "    response = stub.GetModelMetadata(request, 10)\n",
        "    # signature of loaded model is available here: response.metadata['signature_def']\n",
        "    return response.model_spec.version.value\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\nCreate RPC connection ...\")\n",
        "    stub = get_stub()\n",
        "    while True:\n",
        "        print(\"\\nEnter an Amazon review [:q for Quit]\")\n",
        "        if sys.version_info[0] <= 3:\n",
        "            sentence = raw_input() if sys.version_info[0] < 3 else input()\n",
        "        if sentence == ':q':\n",
        "            break\n",
        "        model_input = [sentence]\n",
        "        model_prediction = get_model_prediction(model_input, stub)\n",
        "        print(\"The model predicted ...\")\n",
        "        print(model_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TidfRe2VZU39"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA3wNmDSZU66"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "deploy-TF-Serving.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}